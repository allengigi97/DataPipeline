{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9505975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_file = 'isd-history.csv'\n",
    "output_file = 'qualified.csv'\n",
    "\n",
    "with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        if int(row['BEGIN']) < 20140000 and int(row['END']) > 20240000:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f2c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "input_file = 'qualified.csv'\n",
    "output_file = 'random_station_id.txt'\n",
    "\n",
    "with open(input_file, 'r', newline='') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    rows = list(reader)  # Convert reader object to a list of dictionaries\n",
    "\n",
    "    random_rows = random.sample(rows, 10)\n",
    "\n",
    "# Combine columns 'USAF' and 'WBAN' into a new column 'station_id' for selected rows\n",
    "combined_rows = [{'station_id': row['USAF'] + '-' + row['WBAN']} for row in random_rows]\n",
    "\n",
    "# Write the values of 'station_id' column to a new txt file, separated by newlines\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for row in combined_rows:\n",
    "        outfile.write(row['station_id'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e68542",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "Download data from [NOAA]() for 10 stations each year from 2014 to 2024.\n",
    "\n",
    "# process\n",
    "Understand the meaning of gz file's name\n",
    "[Image]\n",
    "The gz files name's format is ${USAF number}-${WBAN number}-${year}\n",
    "And we can get all the station number information in  the ish-history.csv file\n",
    "Download isd-history.csv\n",
    "Type the command below to download file\n",
    "wget --mirror ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv\n",
    "\n",
    "Use python (on jupyter notebook) to filter qualified station\n",
    "import csv\n",
    "\n",
    "input_file = 'isd-history.csv'\n",
    "output_file = 'qualified.csv'\n",
    "\n",
    "with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        if int(row['BEGIN']) < 20140000 and int(row['END']) > 20240000:\n",
    "            writer.writerow(row)\n",
    "A new file - qualified.csv has been created, which contains qualified station info.\n",
    "Use python (on jupyter botebook)  to randomly get 10 station ids, and store them into txt file\n",
    "import csv\n",
    "import random\n",
    "\n",
    "input_file = 'qualified.csv'\n",
    "output_file = 'random_station_id.txt'\n",
    "\n",
    "with open(input_file, 'r', newline='') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    rows = list(reader)  # Convert reader object to a list of dictionaries\n",
    "\n",
    "    random_rows = random.sample(rows, 10)\n",
    "\n",
    "# Combine columns 'USAF' and 'WBAN' into a new column 'station_id' for selected rows\n",
    "combined_rows = [{'station_id': row['USAF'] + '-' + row['WBAN']} for row in random_rows]\n",
    "\n",
    "# Write the values of 'station_id' column to a new txt file, separated by newlines\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for row in combined_rows:\n",
    "        outfile.write(row['station_id'] + '\\n')\n",
    "Generate a new txt file which contains 10 station ids.\n",
    "[Image]\n",
    "Write a download.sh to download files\n",
    "#!/bin/bash\n",
    "\n",
    "# Define an array of subdirectories\n",
    "subdirectories=(\"2014\" \"2015\" \"2016\" \"2017\" \"2018\" \"2019\" \"2020\" \"2021\" \"2022\" \"2023\" \"2024\")\n",
    "\n",
    "# Read patterns from random_station_id.txt\n",
    "while IFS= read -r pattern; do\n",
    "    # Loop over each subdirectory\n",
    "    for subdir in \"${subdirectories[@]}\"; do\n",
    "        # Use wget to download files matching the current pattern from each subdirectory\n",
    "        wget -r -A \"$pattern*\" \"ftp://ftp.ncdc.noaa.gov/pub/data/noaa/$subdir\"\n",
    "    done\n",
    "done < random_station_id.txt\n",
    "\n",
    "Copy random_station_id.txt which is generated before to the same directory as bash file\n",
    "Open command line, type command below\n",
    "chmod -x download.sh\n",
    "\n",
    "./download.sh\n",
    "\n",
    "Problem\n",
    "Although we already filter stations which start > 2014 and end > 2024, I still find it is possible that there is no data about a station in a specific year.\n",
    "10 stations is not a large amount, and only 2 stations are missing, so I manually identified the missing station and added other station data......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
